# IRON: iron_headers
#
# Distribution A
#
# Approved for Public Release, Distribution Unlimited
#
# EdgeCT (IRON) Software Contract No.: HR0011-15-C-0097
# DCOMP (GNAT)  Software Contract No.: HR0011-17-C-0050
# Copyright (c) 2015-20 Raytheon BBN Technologies Corp.
#
# This material is based upon work supported by the Defense Advanced
# Research Projects Agency under Contracts No. HR0011-15-C-0097 and
# HR0011-17-C-0050. Any opinions, findings and conclusions or
# recommendations expressed in this material are those of the author(s)
# and do not necessarily reflect the views of the Defense Advanced
# Research Project Agency.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
# IRON: end
#
# See also example_bpf_developer.cfg for additional configuration options
# used for debugging, BBN-internal demonstration purposes, and controlling/
# configuring features that are not well-tested and/or not recommended.

################# LOGGING #######################################
#
# Set default log levels.
# Options are:
#   F = FATAL (application will abort with a core file generated)
#   E = ERROR
#   W = WARN
#   I = INFO
#   A = ANALYSIS
#   D = DEBUG
#
Log.DefaultLevel FEW

#
# Set class specific log levels. These override the DefaultLevel just for
# log messages within the specified class.
#
#Log.ClassLevels    <class1>=FEWAID;<class2>=FEWI
# For maximum packet tracking, use:
#Log.ClassLevels    Packet=FEWAID;PacketPool=FEWAID

################# FORWARDING ALGORITHM ##########################
#
# The BPF packet forwarding algorithm (Base or LatencyAware).
#
# Base will ignore time-to-go indications on services and treat all traffic
# as latency-insensitive. LatencyAware will process packets off queues in
# order of latency requirements and will prune paths based on time-to-reach
# compared to time-to-go.
#
# Default value is LatencyAware.
#
#Bpf.Alg.Fwder LatencyAware

#
# The Anti-Circulation mechanism for the forwarding algorithm.
# May be None, HeuristicDAG, or ConditionalDAG.
#
# None will not prevent packet circulation.
# HeuristicDAG will avoid sending latency-sensitive packets back to a
# previously-visited neighbor.
# ConditionalDAG will avoid sending a packet to a previously-visited node,
# even if that node is several hops away.
# In both HeuristicDAG and ConditionalDAG, packets whose only latency-feasible
# paths are through already-visited neighbors will be sent along the
# lowest-latency path.
#
# Default is None for the Base forwarder, HeuristicDAG for LatencyAware.
#
#Bpf.Alg.AntiCirculation HeuristicDAG

#
# Set how deep to look in the queue beyond the first packet if using
# LatencyAware forwarding.
# This allows the BPF to find latency-sensitive packets to send along a link
# even if the first packets in the queue cannot be sent due to time-to-reach
# limitations or anti-circulation rules.
# Increasing this number increases the goodput at the expense of performance
# (in terms of packet processing rate).
#
# Default value is 5000.
#
#Bpf.Alg.QueueSearchDepth 5000

#
# The latency-sensitive (Expedited Forwarding / EF) packet ordering technique.
# May be be None, DeliveryMargin, or Ttg
#
# None does no sorting on the queues, which is effectively first in first out,
# or ordered by receive time.
# DeliveryMargin sorts by time-to-go minus minimum time-to-reach, which is
# effectively a measure of how tight the deadline is for handling this packet.
# Ttg sorts by time-to-go, independent of time-to-reach.
# Sorting the packets in the queues decreases queuing delay on the most
# latency sensitive packets, particularly in cases where there is a high
# percentage of latency-sensitive traffic (compared to total traffic) and
# where there are a variety of deadlines.
#
# Default value is DeliveryMargin.
#
#Bpf.Alg.EFOrdering  None

#
# If Multi Dequeue is enabled, the BPF will dequeue multiple packets at the
# same time as long as the gradient difference is large enough to admit
# multiple packets.  This gives a performance gain, since multiple packets are
# affected by a single BPF decision loop. Using MultiDeq makes the BPF more
# discrete (as opposed to continuous), since decisions are made as chunks
# without time for additional enqueues to be considered.
#
# Default value is true.
#
#Bpf.Alg.MultiDeq true

#
# The BPF low water mark. If the CAT transmit buffer already has at least this
# many bytes, then the BPF will not send any additional packets to this
# neighbor.
#
# Adjusting this value tweaks how full the CAT buffers are kept when the
# system is busy.
#
# Default value is 2000.
#
#Bpf.XmitBufFreeThreshBytes 2000

#
# The BPF multi-dequeue high water mark. Regardless of the difference in
# gradient, the BPF will never dequeue more than this many bytes in a single
# iteration.
#
# Adjusting this value (much like turning MultiDeq on or off) affects how
# discrete vs continuous the BPF process is. If this value is very high, then
# the BPF will chunk together a lot of packets (when the gradient
# allows). This could lead to large queue depth oscillations, since packets
# will effectively burst out over the different CATs. If this value is too
# low, the performance benefit of multi dequeue is lost.
#
# Default value is 6000.
#
#Bpf.XmitQueueThreshBytes 6000

#
# How often (in milliseconds) to send LSAs.
#
# Increasing this will decrease overhead (increase goodput) at the expense
# of up-to-date latency estimates for LatencyAware forwarding. Decreasing this
# will increase the quality of latency estimates and help on-time delivery
# at the expense of extra overhead.
#
# Default value is 1000.
#
#Bpf.LsaIntervalMs 1000

#
# The portion of every link's capacity for QLAMs (0.01 = 1%).
# Increasing this will decrease goodput (by increasing IRON overhead), but
# will speed up backpressure signaling and thus result in fewer queue depth
# oscillations, more accurate utility/goodput optimization (subject to the
# increased overhead), and faster reaction times. Decreasing this value will
# decrease overhead and thus increase throughput at the expense of
# backpressure optimization.
#
# Default value is 0.01
#
#Bpf.QlamOverheadRatio 0.01


################# QUEUES AND QUEUE VALUES########################

#
# The QueueDepth Manager.
# Base, EWMA, HvyBall, or NPLB
#
# Recommendation is to use Base or EWMA.
#
# Base uses exact queue depth values for backpressure signaling.
#
# EWMA smooths queue depths over the observed period of oscillation in order
# to remove oscillations.
#
# HvyBall (has not been tested with all other IRON features) uses the
# heavyball algorithm to reduce latency on queues.
#
# NPLB implements the No Packet Left Behind algorithm for starvation
# avoidance. (NPLB is an alternative to AntiStarvationZombies, the preferred
# IRON anti-starvation mechanism).
#
#Bpf.Alg.QDMgr Base

#
# The maximum number of packets allowed per queue.
#
# IRON queues are stored as linked lists of packet ids. The physical packets
# are stored in shared memory, and the limit on the number of packets (shared
# across all components on the system) is found and configured via the
# constant packet_pool_shm.h::kShmPPNumPkts.
# This parameter stores the maximum length of the (dynamically-sized) linked
# list for each BPF queue. Note that there is a separate queue (each with this
# limit) for each latency class for each destination bin. If this queue length
# is reached, additional packets are dropped (tail dropping).
#
# Default value is 50000
#
#Bpf.QueueSet.MaxBinDepthPkts  50000

#
# True to drop zombies when received instead of enqueuing.
#
# This parameter is here because the notion of adding zombies (for features
# like Zombie Latency Reduction and Anti-Starvation) and of zombifying expired
# latency sensitive packets is a novel IRON addition to backpressure, and
# keeping zombies as they travel through the network is more inline with
# traditional backpressure than dropping them, and thus may be something to
# explore if looking into theoretical performance of IRON. The default value
# is true because keeping zombies downstream of their source does more harm
# (building up queues with artificial packets outside the control of the
# current node) than good.
#
# Default value is true.
#
#Bpf.DropRcvdZombies true

#
# True to enable "ASAP" (Anti-Starvation with Artificial Packets) to prevent
# starvation due to low-rate flows. If true, the BPF will detect starved
# bins and add zombies at a rate of approximately head-of-line-delay^2 until
# starvation is overcome.
#
# Note: if this is true and QDMgr = NPLB, the system will immediately abort
# as misconfigured, since NPLB is an alternative mechanism for avoiding
# starvation and the two cannot be used together.
#
# Default is true
#
#Bpf.UseAntiStarvationZombies true

#
# True to generate on-the-fly XPLOT graphs of the per-destination
# queue depths. These graphs (which will be placed in the log directories
# under the name queue_depths_<dest_bin_id>.xplot) have proven very helpful
# for understanding BPF behavior, and can be viewed with the xplot
# application (www.xplot.org).
# Enabling this option will do nothing unless the XPLOT compile option is also
# enabled in options.mk.
#
# Default is false.
#
#Bpf.GenerateQueueDepthsGraphs false


################# UNDER-LOADED NETWORKS #########################

#
# When the Hysteresis is greater than 0, backpressure gradients must surpass
# the hysteresis before any packets will be sent. In other words, if two
# neighboring queue depths for the same bin are exactly equal (or within the
# hysteresis of each other), the BPF will not forward any packets for that
# bin to that neighbor. Having a non-zero hysteresis reduces circulation in
# an underloaded network.
#
# Default value is 150.
#
#Bpf.Alg.HysteresisBytes 150

#
# The factor by which to multiply the number of hops to obtain a virtual queue
# depth in bytes, for all bins.
#
# This value is paired with Bpf.VirtQueueDepths.X.Hops below, which includes
# the full description of how virtual queue depths are configured and used.
#
# The default value is 0, which results in no virtual queues.
#
#Bpf.VirtQueueDepths.Multiplier  1100

#
# Configuration parameters defining the topology to be used when settings up
# virtual queues.
#
# Virtual queues are used to coerce packets to move towards the destination
# in a lightly-loaded network. When virtual queues are defined, backpressure
# gradients are computed based on the sum of the actual queue depths plus the
# virtual queue depths. By having virtual queue depths defined based on the
# number of hops away the destination is from the current node, IRON
# effectively creates a gradient moving towards the destination even without
# any real queues.
#
# These parameters are defined as follows:
# Bpf.VirtQueueDepths.<src-bin-id>.Hops <dst-bin-id>:<num>,<dst-bin-id>:<num>,<dst-bin-id:<num>
# The bin id in the parameters name specifies the node where these virtual
# queue depths will be applied. The remaining bin ids (in the parameter value
# string) indicate the destination bin id for which the virtual queue depth
# will be defined. The <num>s indicate the number of hops from the current
# node to that destination.
#
# For example, if the topology is 1--2--3, the following values would be
# correct. Bin 2 is one hop from bin 1, bin 3 is two hops from bin 1.
#
# An unspecified neighbor has a virtual queue depth of 0, but if there is not
# a configuration line item for each bin id, then virtual queues will not be
# used at all.
#
#Bpf.VirtQueueDepths.1.Hops  2:1,3:2
#Bpf.VirtQueueDepths.2.Hops  1:1,3:1
#Bpf.VirtQueueDepths.3.Hops  1:2,2:1


################# ZOMBIE LATENCY REDUCTION ######################
# The default parameter values for this algorithm have been well
# tested under a variety of experiments.

#
# True to enable the ZLR (Zombie Latency Reduction) algorithm.
#
# If this is enabled, then zombies will be slowly added to all queues over a
# certain threshold, effectively replacing real packets in the queue over
# time. The advertised queue length remains the same, so packets are enqueued
# and dequeued at the same rate as if ZLR is disabled, and goodput should be
# the same with and without ZLR. However, by padding the queue with zombies,
# queuing delay is significantly decreased.
#
# Default is true.
#
#Bpf.ZombieLatencyReduction true

#
# Queue depth threshold (of non-zombie packets) in Bytes above which ZLR will
# add zombie packets for the sake of reducing latency.
#
# Decreasing this will decrease latency but may affect system performance
# (throughput or prioritization). Increasing this will increase latency.
# This value must be greater than or equal to Bpf.ZLR.LowWaterMarkBytes.
#
# Default value is 6000 B.
#
#Bpf.ZLR.HighWaterMarkBytes 6000

#
# True to use a dynamic time window over which ZLR looks at queue depth
# minimums to determine a safe/good number of zombies to add.
#
# If this is true, than ZLR will effectively learn the right length of time to
# observe queue depths in order to avoid increasing zombies due to short-term
# spikes or queue depth oscillations but increase zombies when the queue depth
# is actually growing. This assumes that past queue depth patterns are
# indicative of future queue depth patterns. If false, the queue depth window
# is fixed at Bpf.ZLR.DynamicWindowInitialSecs seconds.
#
# Default is true.
#
#Bpf.ZLR.DynamicWindow true

#
# Queue depth threshold (of non-zombie packets) in Bytes below which ZLR will
# increase the ZLR dynamic min depth window (if Bpf.ZLR.DynamicWindow is true).
# Ignored if Bpf.ZLR.DynamicWindow is false.
#
# Decreasing this will be more aggresive about preventing zombie transmission,
# which could help goodput in cases with very dynamic queue depths, but will
# make the system less responsive (in terms of maintaining low latency) to
# network changes.
# Increasing this may make us more likely to send zombies, which could hurt
# goodput, but will result in lower latencies, especially when recovering
# from a change.
# This value must be less than or equal to Bpf.ZLR.HighWaterMarkBytes.
#
# Default value is 2000 B.
#
#Bpf.ZLR.LowWaterMarkBytes 2000

#
# Initial size in seconds of the window over which to look at queue depth
# minimums to determine a safe/good number of zombies to add. This will be
# the constant window if Bpf.ZLR.DynamicWindow is false.
#
# If Bpf.ZLR.DynamicWindow is true, this value is only used fleetingly until a
# better value is learned.  If Bpf.ZLR.DynamicWindow is false, than a higher
# number here will mean ZLR adds zombies more slowly (and thus may have higher
# queue delay), but ZLR will be less likely to over-add zombies and thus less
# likely to waste goodput by sending zombies or by having no real packets in
# the queue. A lower number results in lower queue delay but more likelihood
# of sending zombies.
#
# Default value is 1 second.
#
#Bpf.ZLR.DynamicWindowInitialSecs 1.0

#
# Minimum size in seconds of the window over which to look at queue depth
# minimums to determine a safe/good number of zombies to add. This will be
# ignored if Bpf.ZLR.DynamicWindow is false.
#
# Default value is 200 ms (0.2).
#
#Bpf.ZLR.DynamicWindowLowerBoundSecs 0.2

#
# Maximum size in seconds of the window over which to look at queue depth
# minimums to determine a safe/good number of zombies to add. This will be
# ignored if Bpf.ZLR.DynamicWindow is false.
#
# Default value is 5 seconds.
#
#Bpf.ZLR.DynamicWindowUpperBoundSecs 5.0


################# QUEUE SMOOTHING ###############################
# Many configuration parameters are included here because this is
# a relatively new algorithm and good values for these parameters
# have not yet been determined.

#
# True to observe the queue depth oscillation period and use that period to
# automatically adjust the tau (smoothing) parameter for EWMA. If false, this
# will use Bpf.EWMA.TauUsec the entire time.
# This is ignored if Bpf.Alg.QDMgr is not EWMA.
#
# Default value is true.
#
#Bpf.EWMA.DynamicTau true

#
# The EWMA queue manager tau value (in microseconds).
#
# If Bpf.EWMA.DynamicTau is true, this will just be the initial value which
# will be automatically adjusted based on the observed period of queue depth
# oscillations. If Bpf.EWMA.DynamicTau is false, the queue depths will always
# be smoothed over this time window.
#
# Default value is 5000 (5 ms)
#
#Bpf.EWMA.TauUsec 5000

#
# Number of samples (taken every FftSampleTimeSecs) used when computing the
# FFT for queue depth oscillations.
#
# The total time over which oscillation reduction will compute the FFT is
# Bpf.Osc.FftSampleSize * Bpf.Osc.FftSampleTimeSecs
#
# Default value is 2048.
#
#Bpf.Osc.FftSampleSize 2048

#
# How often to collect a sample for computing FFT for queue depth
# oscillations.
#
# Default value is 2.5 ms.
#
#Bpf.Osc.FftSampleTimeSecs 0.0025

#
# How often to recompute the FFT for queue depth oscillations.
#
# Note that some samples may be used in multiple computations or no
# computations, depending on how this value compares with
# Bpf.Osc.FftSampleSize * Bpf.Osc.FftSampleTimeSecs
#
# Default value is 1.0.
#
#Bpf.Osc.FftComputeTimeSecs 1.0

#
# Value for the largest queue depth oscillation period to be used for queue
# depth smoothing.
#
# Increasing this means oscillation reduction may smooth over a long period if
# there are long oscillations, which means instantaneous queue depth values
# may have very little effect on the backpressure signaling. Decreasing this
# means long oscillations will be ignored (rather than smoothed away).
#
# Default value is 1.0 second.
#
#Bpf.Osc.MaxConsideredPeriodSecs 1.0

#
# How long to wait for queue depths to converge after resetting the
# oscillation computation. After this time, oscillation reduction assume it's
# converged and reset it again if the queues still appear to be oscillating.
#
# This is meant to be a reflection of the maximum convergence time in the
# system. Further research may make it possible to automatically compute this
# or may make it unnecessary.
#
# Default value is 6.0.
#
#Bpf.Osc.MinTimeBetweenResetsSecs 6.0

#
# If the actual queue depth value differs from the smoothed value by at
# least this fraction of the smoothed value for at least ResetTriggerTimeSecs,
# reset the oscillation computations.
#
# Default value is 0.25.
#
#Bpf.Osc.ResetTriggerFraction 0.25

#
# If the smoothed queue depth values are off from the actual queue depth
# values for at least this long, reset the oscillation computations.
#
# Default value is 0.375.
#
#Bpf.Osc.ResetTriggerTimeSecs 0.375

################ INTERFACE WITH ADMISSION PLANNER ############################

# The statistics collection interval, in milliseconds. When this
# interval expires, the collected statistics are cleared and logged if
# LogStatistics is true.
#
# These statistics are used to communicate values to the admission planner.
# They can also be used for debugging and/or custom operation views.
#
# Default value: 5000
#
# StatsCollectionIntervalMs  5000

# Controls if the collected statistics are written to the Log file.
#
# Default value: true
#
# LogStatistics  true
